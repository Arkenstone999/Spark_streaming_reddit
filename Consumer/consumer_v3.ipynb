{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460b9602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf, col, from_unixtime\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ebc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/08 22:05:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Connecting to producer at host.docker.internal:9998\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark\n",
    "spark_conf = SparkConf().setAppName('RedditPipeline')\n",
    "ss1 = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "\n",
    "# Command to run spark server on docker to plug into kernel for running notebook\n",
    "# docker run -it -p 4040:4040 -p 8080:8080 -p 8081:8081 -p 8888:8888 -p 5432:5432 --cpus=2 --memory=2048m -h spark -w /mnt/host_home/ pyspark_container jupyter-lab --ip 0.0.0.0 --port 8888 --no-browser --allow-root \n",
    "\n",
    "# Configuration\n",
    "RAW_CHECKPOINT_PATH = './checkpoints/raw'\n",
    "RAW_PATH = './data/raw'\n",
    "METRICS_CHECKPOINT_PATH = './checkpoints/metrics'\n",
    "METRICS_PATH = './data/metrics'\n",
    "\n",
    "HOST = \"host.docker.internal\" # change to '127.0.0.1' if not using Docker\n",
    "PORT = '9998'\n",
    "\n",
    "USERS_REGEX = r'/u/([a-zA-Z0-9_-]+)' \n",
    "SUBREDDITS_REGEX = r'/r/([a-zA-Z0-9_-]+)' \n",
    "URLS_REGEX = r'(https?://[^\\s]+)'\n",
    "\n",
    "print(f\"→ Connecting to producer at {HOST}:{PORT}\")\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField('type', StringType(), True),\n",
    "    StructField('subreddit', StringType(), True),\n",
    "    StructField('id', StringType(), True),\n",
    "    StructField('text', StringType(), True),\n",
    "    StructField('created_utc', DoubleType(), True),\n",
    "    StructField('author', StringType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe64156",
   "metadata": {},
   "source": [
    "### Function to extract references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426cd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_references(batch):\n",
    "    \"\"\"\n",
    "    Extract references of users, subreddits and URLs from the text of each post or comment.\n",
    "    \"\"\"\n",
    "    references = batch \\\n",
    "        .withColumn('users', F.regexp_extract_all(F.col('text'), F.lit(USERS_REGEX), 1)) \\\n",
    "        .withColumn('subreddits', F.regexp_extract_all(F.col('text'), F.lit(SUBREDDITS_REGEX), 1)) \\\n",
    "        .withColumn('urls', F.regexp_extract_all(F.col('text'), F.lit(URLS_REGEX), 1))\n",
    "\n",
    "    references = references.withWatermark('created_utc', '1 minute') \\\n",
    "        .groupBy(F.window(F.col(\"timestamp\"), windowDuration='60 seconds', slideDuration='5 seconds')) \\\n",
    "        .agg(\n",
    "            F.collect_list('users').alias('users'),\n",
    "            F.collect_list('subreddits').alias('subreddits'),\n",
    "            F.collect_list('urls').alias('urls'),\n",
    "            F.sum(F.size('users')).alias('users_count'),\n",
    "            F.sum(F.size('subreddits')).alias('subreddits_count'),\n",
    "            F.sum(F.size('urls')).alias('urls_count')\n",
    "        )\n",
    "    \n",
    "    return references\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5935102",
   "metadata": {},
   "source": [
    "### Custom batch processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a0b397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_df, batch_id):\n",
    "    print(f\"==== Processing batch {batch_id} ====\")\n",
    "\n",
    "    # create temporary table for raw data and save it to disk\n",
    "    batch_df.createOrReplaceTempView(\"raw\")\n",
    "    batch_df.write.mode(\"append\").json(RAW_PATH)\n",
    "\n",
    "    # convert created_utc to timestamp\n",
    "    batch_df = batch_df.withColumn(\"timestamp\", from_unixtime(col(\"created_utc\")).cast(\"timestamp\"))\n",
    "\n",
    "    # TODO: Implement the references in a window of 60 seconds with a sliding window of 5 seconds\n",
    "    references_df = extract_references(batch_df)\n",
    "    references_df.show(5, truncate=False)\n",
    "    # TODO: implement tf-idf to find the top 10 most relevant words in the text\n",
    "    # TODO: perform sentiment analysis on the text and add a column with the sentiment score\n",
    "    \n",
    "    # create temporary table for metrics and save it to disk\n",
    "    batch_df.createOrReplaceTempView(\"metrics\")\n",
    "    batch_df.write.mode(\"append\").json(METRICS_PATH)\n",
    "\n",
    "    batch_df.write \\\n",
    "        .mode(\"append\") \\\n",
    "        .json(METRICS_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68559d21",
   "metadata": {},
   "source": [
    "### Stream data from Producer into Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "493af196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:05:50 WARN TextSocketSourceProvider: The socket source should not be used for production applications! It does not support recovery.\n"
     ]
    }
   ],
   "source": [
    "# Read from socket without schema (will get string data)\n",
    "streaming_df = ss1.readStream \\\n",
    "\t.format(\"socket\") \\\n",
    "\t.option(\"host\", HOST) \\\n",
    "\t.option(\"port\", PORT) \\\n",
    "\t.load()\n",
    "# Parse the JSON string and apply schema after loading\n",
    "\n",
    "streaming_df = streaming_df.select(F.from_json(F.col(\"value\"), schema).alias(\"data\")).select(\"data.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68386f5",
   "metadata": {},
   "source": [
    "### Start processing stream in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d571cd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 22:05:53 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0xffc8c9807450>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Processing batch 0 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----------+----+\n",
      "|window|users|subreddits|urls|\n",
      "+------+-----+----------+----+\n",
      "+------+-----+----------+----+\n",
      "\n",
      "==== Processing batch 1 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+--------+----------+--------+\n",
      "|window                                    |users   |subreddits|urls    |\n",
      "+------------------------------------------+--------+----------+--------+\n",
      "|{2025-06-08 18:50:35, 2025-06-08 18:51:35}|[[]]    |[[]]      |[[]]    |\n",
      "|{2025-06-08 19:08:15, 2025-06-08 19:09:15}|[[]]    |[[]]      |[[]]    |\n",
      "|{2025-06-08 19:57:05, 2025-06-08 19:58:05}|[[]]    |[[]]      |[[]]    |\n",
      "|{2025-06-08 20:49:30, 2025-06-08 20:50:30}|[[], []]|[[], []]  |[[], []]|\n",
      "|{2025-06-08 19:24:50, 2025-06-08 19:25:50}|[[]]    |[[]]      |[[]]    |\n",
      "+------------------------------------------+--------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 2 ====\n",
      "+------------------------------------------+------------+------------+------------+\n",
      "|window                                    |users       |subreddits  |urls        |\n",
      "+------------------------------------------+------------+------------+------------+\n",
      "|{2025-06-08 21:29:15, 2025-06-08 21:30:15}|[[]]        |[[]]        |[[]]        |\n",
      "|{2025-06-08 21:28:05, 2025-06-08 21:29:05}|[[]]        |[[]]        |[[]]        |\n",
      "|{2025-06-08 21:30:15, 2025-06-08 21:31:15}|[[], [], []]|[[], [], []]|[[], [], []]|\n",
      "|{2025-06-08 21:21:25, 2025-06-08 21:22:25}|[[]]        |[[]]        |[[]]        |\n",
      "|{2025-06-08 21:33:00, 2025-06-08 21:34:00}|[[]]        |[[]]        |[[]]        |\n",
      "+------------------------------------------+------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 3 ====\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|window                                    |users|subreddits|urls|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|{2025-05-27 18:22:00, 2025-05-27 18:23:00}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:04:55, 2025-06-08 22:05:55}|[[]] |[[]]      |[[]]|\n",
      "|{2025-05-26 21:04:05, 2025-05-26 21:05:05}|[[]] |[[]]      |[[]]|\n",
      "|{2025-05-27 17:13:50, 2025-05-27 17:14:50}|[[]] |[[]]      |[[]]|\n",
      "|{2025-05-28 04:25:10, 2025-05-28 04:26:10}|[[]] |[[]]      |[[]]|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 4 ====\n",
      "+------------------------------------------+-----+----------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|window                                    |users|subreddits|urls                                                                                                                                       |\n",
      "+------------------------------------------+-----+----------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{2025-05-28 20:31:20, 2025-05-28 20:32:20}|[[]] |[[]]      |[[]]                                                                                                                                       |\n",
      "|{2025-05-29 07:15:25, 2025-05-29 07:16:25}|[[]] |[[]]      |[[https://www.marketcapwatch.com/canada/largest-companies-in-canada/](https://www.marketcapwatch.com/canada/largest-companies-in-canada/)]]|\n",
      "|{2025-05-28 20:31:40, 2025-05-28 20:32:40}|[[]] |[[]]      |[[]]                                                                                                                                       |\n",
      "|{2025-05-29 07:16:10, 2025-05-29 07:17:10}|[[]] |[[]]      |[[https://www.marketcapwatch.com/canada/largest-companies-in-canada/](https://www.marketcapwatch.com/canada/largest-companies-in-canada/)]]|\n",
      "|{2025-05-28 16:43:05, 2025-05-28 16:44:05}|[[]] |[[]]      |[[https://whatwereseeing.com/social-portal/?civicscience-widget-question=741522)]]                                                         |\n",
      "+------------------------------------------+-----+----------+-------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 5 ====\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|window                                    |users|subreddits|urls|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|{2025-05-30 16:50:05, 2025-05-30 16:51:05}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-01 22:42:25, 2025-06-01 22:43:25}|[[]] |[[]]      |[[]]|\n",
      "|{2025-05-31 10:36:40, 2025-05-31 10:37:40}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-01 22:43:00, 2025-06-01 22:44:00}|[[]] |[[]]      |[[]]|\n",
      "|{2025-05-30 16:49:55, 2025-05-30 16:50:55}|[[]] |[[]]      |[[]]|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 6 ====\n",
      "+------------------------------------------+-----+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|window                                    |users|subreddits|urls                                                                                                                                                                                                                                                                        |\n",
      "+------------------------------------------+-----+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{2025-06-03 06:09:40, 2025-06-03 06:10:40}|[[]] |[[]]      |[[https://github.com/chilly23/Roller-coaster-of-Gods)]]                                                                                                                                                                                                                     |\n",
      "|{2025-06-03 06:09:30, 2025-06-03 06:10:30}|[[]] |[[]]      |[[https://github.com/chilly23/Roller-coaster-of-Gods)]]                                                                                                                                                                                                                     |\n",
      "|{2025-06-02 13:00:40, 2025-06-02 13:01:40}|[[]] |[[]]      |[[https://www.ft.com/content/9ca05517-b3fb-46f1-9cde-866061e816a7](https://www.ft.com/content/9ca05517-b3fb-46f1-9cde-866061e816a7), https://gist.github.com/cavedave/c3738c3819afdcb91db20db7f2fbcc09](https://gist.github.com/cavedave/c3738c3819afdcb91db20db7f2fbcc09)]]|\n",
      "|{2025-06-02 07:18:05, 2025-06-02 07:19:05}|[[]] |[[]]      |[[]]                                                                                                                                                                                                                                                                        |\n",
      "|{2025-06-02 06:13:05, 2025-06-02 06:14:05}|[[]] |[[]]      |[[https://www.marketcapwatch.com/france/largest-companies-in-france/](https://www.marketcapwatch.com/france/largest-companies-in-france/)]]                                                                                                                                 |\n",
      "+------------------------------------------+-----+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 7 ====\n",
      "+------------------------------------------+-----+----------+---------------------------------------------------------------------------------------------------------------------+\n",
      "|window                                    |users|subreddits|urls                                                                                                                 |\n",
      "+------------------------------------------+-----+----------+---------------------------------------------------------------------------------------------------------------------+\n",
      "|{2025-06-03 17:12:25, 2025-06-03 17:13:25}|[[]] |[[]]      |[[]]                                                                                                                 |\n",
      "|{2025-06-03 21:19:15, 2025-06-03 21:20:15}|[[]] |[[]]      |[[]]                                                                                                                 |\n",
      "|{2025-06-03 17:13:05, 2025-06-03 17:14:05}|[[]] |[[]]      |[[]]                                                                                                                 |\n",
      "|{2025-06-03 13:40:15, 2025-06-03 13:41:15}|[[]] |[[]]      |[[]]                                                                                                                 |\n",
      "|{2025-06-03 22:45:45, 2025-06-03 22:46:45}|[[]] |[[]]      |[[https://explore-education-statistics.service.gov.uk/data-catalogue/data-set/2f6bffba-735d-4801-8ae3-f0f058044da4)]]|\n",
      "+------------------------------------------+-----+----------+---------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 8 ====\n",
      "+------------------------------------------+-----+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|window                                    |users|subreddits|urls                                                                                                                                                                                                                                                                                          |\n",
      "+------------------------------------------+-----+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{2025-06-05 15:08:40, 2025-06-05 15:09:40}|[[]] |[[]]      |[[https://adsb.exposed/?dataset=Birds](https://adsb.exposed/?dataset=Birds), https://clickhouse.com/blog/birds](https://clickhouse.com/blog/birds), https://science.ebird.org/en/use-ebird-data)., https://github.com/ClickHouse/adsb.exposed/](https://github.com/ClickHouse/adsb.exposed/)]]|\n",
      "|{2025-06-04 14:11:40, 2025-06-04 14:12:40}|[[]] |[[]]      |[[]]                                                                                                                                                                                                                                                                                          |\n",
      "|{2025-06-04 19:40:20, 2025-06-04 19:41:20}|[[]] |[[]]      |[[]]                                                                                                                                                                                                                                                                                          |\n",
      "|{2025-06-04 14:43:25, 2025-06-04 14:44:25}|[[]] |[[]]      |[[https://www.iea.org/data-and-statistics/data-product/ccus-projects-database#overview)]]                                                                                                                                                                                                     |\n",
      "|{2025-06-04 20:33:40, 2025-06-04 20:34:40}|[[]] |[[]]      |[[]]                                                                                                                                                                                                                                                                                          |\n",
      "+------------------------------------------+-----+----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 9 ====\n",
      "+------------------------------------------+--------+----------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|window                                    |users   |subreddits|urls                                                                                                                   |\n",
      "+------------------------------------------+--------+----------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|{2025-06-05 19:50:15, 2025-06-05 19:51:15}|[[]]    |[[]]      |[[]]                                                                                                                   |\n",
      "|{2025-06-05 15:38:00, 2025-06-05 15:39:00}|[[]]    |[[]]      |[[]]                                                                                                                   |\n",
      "|{2025-06-06 03:59:25, 2025-06-06 04:00:25}|[[], []]|[[], []]  |[[], []]                                                                                                               |\n",
      "|{2025-06-06 00:59:35, 2025-06-06 01:00:35}|[[]]    |[[]]      |[[]]                                                                                                                   |\n",
      "|{2025-06-05 15:55:40, 2025-06-05 15:56:40}|[[]]    |[[]]      |[[https://vote.gov, https://www.senate.gov/senators/senators-contact.htm?Class=1, https://contactrepresentatives.org/]]|\n",
      "+------------------------------------------+--------+----------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 10 ====\n",
      "+------------------------------------------+-----+----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|window                                    |users|subreddits|urls                                                                                                                                                                                                                                                                                                               |\n",
      "+------------------------------------------+-----+----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{2025-06-06 06:59:10, 2025-06-06 07:00:10}|[[]] |[[]]      |[[https://www.marketcapwatch.com/united-kingdom/largest-companies-in-united-kingdom/](https://www.marketcapwatch.com/united-kingdom/largest-companies-in-united-kingdom/)]]                                                                                                                                        |\n",
      "|{2025-06-06 09:37:20, 2025-06-06 09:38:20}|[[]] |[[]]      |[[https://www.metoffice.gov.uk/hadobs/hadcet/data/download.html](https://www.google.com/url?q=https%3A%2F%2Fwww.metoffice.gov.uk%2Fhadobs%2Fhadcet%2Fdata%2Fdownload.html), https://gist.github.com/cavedave/0a0f019b89671829bc60412ab3bb9548](https://gist.github.com/cavedave/0a0f019b89671829bc60412ab3bb9548)]]|\n",
      "|{2025-06-06 09:36:35, 2025-06-06 09:37:35}|[[]] |[[]]      |[[https://www.metoffice.gov.uk/hadobs/hadcet/data/download.html](https://www.google.com/url?q=https%3A%2F%2Fwww.metoffice.gov.uk%2Fhadobs%2Fhadcet%2Fdata%2Fdownload.html), https://gist.github.com/cavedave/0a0f019b89671829bc60412ab3bb9548](https://gist.github.com/cavedave/0a0f019b89671829bc60412ab3bb9548)]]|\n",
      "|{2025-06-06 16:59:50, 2025-06-06 17:00:50}|[[]] |[[]]      |[[https://whatwereseeing.com/social-portal/?civicscience-widget-question=416721)]]                                                                                                                                                                                                                                 |\n",
      "|{2025-06-06 17:00:00, 2025-06-06 17:01:00}|[[]] |[[]]      |[[https://whatwereseeing.com/social-portal/?civicscience-widget-question=416721)]]                                                                                                                                                                                                                                 |\n",
      "+------------------------------------------+-----+----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 11 ====\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|window                                    |users|subreddits|urls|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|{2025-06-08 16:32:30, 2025-06-08 16:33:30}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-07 11:09:40, 2025-06-07 11:10:40}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-06 21:26:25, 2025-06-06 21:27:25}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-07 11:09:45, 2025-06-07 11:10:45}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-07 18:34:50, 2025-06-07 18:35:50}|[[]] |[[]]      |[[]]|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 12 ====\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|window                                    |users|subreddits|urls|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|{2025-06-08 20:18:05, 2025-06-08 20:19:05}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 20:17:45, 2025-06-08 20:18:45}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 20:18:10, 2025-06-08 20:19:10}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 20:18:30, 2025-06-08 20:19:30}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 20:17:55, 2025-06-08 20:18:55}|[[]] |[[]]      |[[]]|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 13 ====\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|window                                    |users|subreddits|urls|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|{2025-06-08 22:07:15, 2025-06-08 22:08:15}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:07:00, 2025-06-08 22:08:00}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:06:50, 2025-06-08 22:07:50}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:06:55, 2025-06-08 22:07:55}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:06:45, 2025-06-08 22:07:45}|[[]] |[[]]      |[[]]|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 14 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+----------+----+\n",
      "|window                                    |users|subreddits|urls|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|{2025-06-08 22:08:55, 2025-06-08 22:09:55}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:08:40, 2025-06-08 22:09:40}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:08:15, 2025-06-08 22:09:15}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:08:10, 2025-06-08 22:09:10}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:08:45, 2025-06-08 22:09:45}|[[]] |[[]]      |[[]]|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 15 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+----------+----+\n",
      "|window                                    |users|subreddits|urls|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|{2025-06-08 22:10:15, 2025-06-08 22:11:15}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:09:45, 2025-06-08 22:10:45}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:09:35, 2025-06-08 22:10:35}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:10:20, 2025-06-08 22:11:20}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:10:25, 2025-06-08 22:11:25}|[[]] |[[]]      |[[]]|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 16 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+----------+----+\n",
      "|window                                    |users|subreddits|urls|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|{2025-06-08 22:12:35, 2025-06-08 22:13:35}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:12:05, 2025-06-08 22:13:05}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:11:55, 2025-06-08 22:12:55}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:12:20, 2025-06-08 22:13:20}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:12:10, 2025-06-08 22:13:10}|[[]] |[[]]      |[[]]|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "==== Processing batch 17 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+----------+----+\n",
      "|window                                    |users|subreddits|urls|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "|{2025-06-08 22:13:35, 2025-06-08 22:14:35}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:13:20, 2025-06-08 22:14:20}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:13:40, 2025-06-08 22:14:40}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:13:05, 2025-06-08 22:14:05}|[[]] |[[]]      |[[]]|\n",
      "|{2025-06-08 22:13:30, 2025-06-08 22:14:30}|[[]] |[[]]      |[[]]|\n",
      "+------------------------------------------+-----+----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "streaming_df.writeStream \\\n",
    "\t.foreachBatch(process_batch) \\\n",
    "    .option(\"checkpointLocation\", METRICS_CHECKPOINT_PATH) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e4aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
